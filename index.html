<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Timoth√©e Schmude </title> <meta name="author" content="Timoth√©e Schmude"> <meta name="description" content="Website of Timoth√©e Schmude. "> <meta name="keywords" content="timothee-schmude, artificial intelligence, explainable ai, contestable ai, university of vienna, ai novices"> <meta property="og:site_name" content="Timoth√©e Schmude"> <meta property="og:type" content="website"> <meta property="og:title" content="Timoth√©e Schmude | about"> <meta property="og:url" content="https://timothee-schmude.github.io//"> <meta property="og:description" content="Website of Timoth√©e Schmude. "> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="about"> <meta name="twitter:description" content="Website of Timoth√©e Schmude. "> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Timoth√©e Schmude"
        },
        "url": "https://timothee-schmude.github.io//",
        "@type": "WebSite",
        "description": "Website of Timoth√©e Schmude.
",
        "headline": "about",
        
        "name": "Timoth√©e Schmude",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://timothee-schmude.github.io//"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Timoth√©e</span> Schmude </h1> <p class="desc"><em>"I was startled to see how quickly and how very deeply people conversing With DOCTOR became emotionally involved with the computer and how unequivocally they anthropomorphized it."</em> - Joseph Weizenbaum in <a href="https://en.wikipedia.org/wiki/Computer_Power_and_Human_Reason" rel="external nofollow noopener" target="_blank">Computer Power and Human Reason</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/timothee_schmude-480.webp 480w,/assets/img/timothee_schmude-800.webp 800w,/assets/img/timothee_schmude-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/timothee_schmude.jpg?45dead64cbca2030b2886724200433df" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="timothee_schmude.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hi! I‚Äôm Timoth√©e, a PhD student at the <a href="https://vda.cs.univie.ac.at/team/person/1001666/#publications" rel="external nofollow noopener" target="_blank">University of Vienna</a> working on explainable and contestable AI. I‚Äôm interested in how explanations help people understand and challenge algorithmic systems and conduct interviews and workshops to investigate these topics. My latest projects look at the information needs of AI novices, explanation design for group decision-making, and regulation of explainable and contestable AI.</p> <p>In the quote above Weizenbaum describes his chatbot ELIZA, which very soon turned into a therapy bot for his colleagues and peers. In turn, he re-baptized it as DOCTOR. It‚Äôs a cute story and a reminder that humans look for humanness in everything.</p> <p>In my free time, I like to go hiking and climbing, and I recently acquired a taste for knitting. I‚Äôm also enthusiastic about all sorts of books, my latest reads include <em><a href="https://en.wikipedia.org/wiki/The_Black_Swan%3A_The_Impact_of_the_Highly_Improbable" rel="external nofollow noopener" target="_blank">The Black Swan</a></em> (NN Taleb), <em><a href="https://en.wikipedia.org/wiki/Surely_You%27re_Joking,_Mr._Feynman!" rel="external nofollow noopener" target="_blank">Surely You‚Äôre Joking, Mr. Feynman!</a></em> (R Feynman), <em><a href="https://www.penguin.co.uk/books/455809/the-trading-game-by-stevenson-gary/9781802062731" rel="external nofollow noopener" target="_blank">The Trading Game</a></em> (G Stevenson), and <em><a href="https://en.wikipedia.org/wiki/Careless_People" rel="external nofollow noopener" target="_blank">Careless People</a></em> (S Wynn-Williams) üìö.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 11, 2025</th> <td> üé§ I had the pleasure to moderate a panel discussion organized by the <a href="https://www.institutfrancais.at/fr/events/novembre-numerique-metaversum" rel="external nofollow noopener" target="_blank">Institut Fran√ßais de Vienne</a> at TU Wien on the topic of virtual and augmented reality and their application in the <a href="https://en.wikipedia.org/wiki/Metaverse" rel="external nofollow noopener" target="_blank">Metaverse</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 15, 2025</th> <td> üìú Our position paper <em><a href="https://doi.org/10.1007/978-3-032-11108-1_14" rel="external nofollow noopener" target="_blank">Start Using JustiÔ¨Åcations When Explaining AI Systems to Decision Subjects</a></em> was accepted to the <em>Digital Humanism Research Conference ‚Äò25</em> and will be presented on the 20th and 21st November in Vienna! </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 01, 2025</th> <td> ü¶â I was accepted to the FAccT ‚Äò25 Doctoral Consortium and will present my work in Athens this June! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://doi.org/10.1007/978-3-032-11108-1_14" rel="external nofollow noopener" target="_blank">DigHum Res 25</a> </abbr> </div> <div id="kolarova_schmude_25" class="col-sm-8"> <div class="title">Start Using Justifications When Explaining AI Systems to¬†Decision Subjects</div> <div class="author"> Kl√°ra Kol√°≈ôov√°,¬†and¬†<em>Timoth√©e Schmude</em> </div> <div class="periodical"> <em>In Digital Humanism</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1007/978-3-032-11108-1_14" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Kolarova%20and%20Schmude%20-%202025%20-%20Start%20Using%20Justifications%20When%20Explaining%20AI%20Systems%20to%C2%A0Decision%20Subjects.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Every AI system that makes decisions about people has stakeholders who are affected by its outcomes. These stakeholders, whom we call decision subjects, have a right to understand how their outcome was produced and to challenge it. Explanations should support this process by making the algorithmic system transparent and creating an understanding of its inner workings. However, we argue that while current explanation approaches focus on descriptive explanations, decision subjects also require normative explanations or justifications. In this position paper, we advocate for justifications as a key component in explanation approaches for decision subjects and make three claims to this end, namely that justifications i) fulfill decision subjects‚Äô information needs, ii) shape their intent to accept or contest decisions, and iii) encourage accountability considerations throughout the system‚Äôs lifecycle. We propose four guiding principles for the design of justifications, provide two design examples, and close with directions for future work. With this paper, we aim to provoke thoughts on the role, value, and design of normative information in explainable AI for decision subjects.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://dl.acm.org/doi/10.1145/3706599.3721096" rel="external nofollow noopener" target="_blank">CHI EA 25</a> </abbr> </div> <div id="schmude2025explainandcontest" class="col-sm-8"> <div class="title">Explainability and Contestability for the Responsible Use of Public Sector AI</div> <div class="author"> <em>Timoth√©e Schmude</em> </div> <div class="periodical"> <em>In Proceedings of the Extended Abstracts of CHI‚Äô 25</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706599.3721096" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Schmude%20et%20al.%20-%202025%20-%20Explainability%20and%20Contestability%20for%20the%20Responsible%20Use%20of%20Public%20Sector%20AI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Public institutions have begun to use AI systems in areas that directly impact people‚Äôs lives, including labor, law, health, and migration. Explainability ensures that these systems are understandable to the involved stakeholders, while its emerging counterpart contestability enables them to challenge AI decisions. Both principles support the responsible use of AI systems, but their implementation needs to take into account the needs of people without technical background, AI novices. I conduct interviews and workshops to explore how explainable AI can be made suitable for AI novices, how explanations can support their agency by allowing them to contest decisions, and how this intersection is conceptualized. My research aims to inform policy and public institutions on how to implement responsible AI by designing for explainability and contestability. The Remote Doctoral Consortium would allow me to discuss with peers how these principles can be realized and account for human factors in their design.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://doi.org/10.1016/j.ijhcs.2024.103380" rel="external nofollow noopener" target="_blank">IJHCS</a> </abbr> </div> <div id="schmude2024_ai_novices" class="col-sm-8"> <div class="title">Information that matters: Exploring information needs of people affected by algorithmic decisions</div> <div class="author"> <em>Timoth√©e Schmude</em>,¬†Laura Koesten,¬†Torsten M√∂ller,¬†and¬†Sebastian Tschiatschek </div> <div class="periodical"> <em>International Journal of Human-Computer Studies</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.ijhcs.2024.103380" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Schmude%20et%20al.%20-%202024%20-%20Information%20That%20Matters_Exploring%20Information%20Needs%20of%20People%20Affected%20by%20Algorithmic%20Decisions.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Every AI system that makes decisions about people has a group of stakeholders that are personally affected by these decisions. However, explanations of AI systems rarely address the information needs of this stakeholder group, who often are AI novices. This creates a gap between conveyed information and information that matters to those who are impacted by the system‚Äôs decisions, such as domain experts and decision subjects. To address this, we present the ‚ÄúXAI Novice Question Bank‚Äù, an extension of the XAI Question Bank (Liao et al., 2020) containing a catalog of information needs from AI novices in two use cases: employment prediction and health monitoring. The catalog covers the categories of data, system context, system usage, and system specifications. We gathered information needs through task based interviews where participants asked questions about two AI systems to decide on their adoption and received verbal explanations in response. Our analysis showed that participants‚Äô confidence increased after receiving explanations but that their understanding faced challenges. These included difficulties in locating information and in assessing their own understanding, as well as attempts to outsource understanding. Additionally, participants‚Äô prior perceptions of the systems‚Äô risks and benefits influenced their information needs. Participants who perceived high risks sought explanations about the intentions behind a system‚Äôs deployment, while those who perceived low risks rather asked about the system‚Äôs operation. Our work aims to support the inclusion of AI novices in explainability efforts by highlighting their information needs, aims, and challenges. We summarize our findings as five key implications that can inform the design of future explanations for lay stakeholder audiences.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://dl.acm.org/doi/abs/10.1145/3593013.3594054" rel="external nofollow noopener" target="_blank">FAccT 23</a> </abbr> </div> <div id="schmude2023" class="col-sm-8"> <div class="title">On the Impact of Explanations on Understanding of Algorithmic Decision-Making</div> <div class="author"> <em>Timoth√©e Schmude</em>,¬†Laura Koesten,¬†Torsten M√∂ller,¬†and¬†Sebastian Tschiatschek </div> <div class="periodical"> <em>In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT)</em>, Chicago, IL, USA, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3593013.3594054" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Schmude%20et%20al.%20-%202023%20-%20On%20the%20Impact%20of%20Explanations%20on%20Understanding%20of%20Algorithmic%20Decision-Making.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Ethical principles for algorithms are gaining importance as more and more stakeholders are affected by "high-risk" algorithmic decision-making (ADM) systems. Understanding how these systems work enables stakeholders to make informed decisions and to assess the systems‚Äô adherence to ethical values. Explanations are a promising way to create understanding, but current explainable artificial intelligence (XAI) research does not always consider existent theories on how understanding is formed and evaluated. In this work, we aim to contribute to a better understanding of understanding by conducting a qualitative task-based study with 30 participants, including users and affected stakeholders. We use three explanation modalities (textual, dialogue, and interactive) to explain a "high-risk" ADM system to participants and analyse their responses both inductively and deductively, using the "six facets of understanding" framework by Wiggins &amp; McTighe [63]. Our findings indicate that the "six facets" framework is a promising approach to analyse participants‚Äô thought processes in understanding, providing categories for both rational and emotional understanding. We further introduce the "dialogue" modality as a valid explanation approach to increase participant engagement and interaction with the "explainer", allowing for more insight into their understanding in the process. Our analysis further suggests that individuality in understanding affects participants‚Äô perceptions of algorithmic fairness, demonstrating the interdependence between understanding and ADM assessment that previous studies have outlined. We posit that drawing from theories on learning and understanding like the "six facets" and leveraging explanation modalities can guide XAI research to better suit explanations to learning processes of individuals and consequently enable their assessment of ethical values of ADM systems.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%74%69%6D%6F%74%68%65%65.%73%63%68%6D%75%64%65@%75%6E%69%76%69%65.%61%63.%61%74" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=clG_VOgAAAAJ&amp;hl" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Timothee-Schmude/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://www.linkedin.com/in/timoth%C3%A9e-schmude-17a032218" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://stackoverflow.com/users/13440007" title="Stackoverflow" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-stack-overflow"></i></a> </div> <div class="contact-note">Don‚Äôt hesitate to get in touch! I'll most quickly answer via mail :-) </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> ¬© Copyright 2025 Timoth√©e Schmude. Built with <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> and <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>, hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Portrait photo credits go to Christopher Werner! </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>