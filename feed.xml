<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://timothee-schmude.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://timothee-schmude.github.io//" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-28T17:18:30+00:00</updated><id>https://timothee-schmude.github.io//feed.xml</id><title type="html">blank</title><subtitle>Website of Timothée Schmude. </subtitle><entry><title type="html">AI and the Registry of Power</title><link href="https://timothee-schmude.github.io//blog/2022/ai-atlas/" rel="alternate" type="text/html" title="AI and the Registry of Power"/><published>2022-11-16T10:00:00+00:00</published><updated>2022-11-16T10:00:00+00:00</updated><id>https://timothee-schmude.github.io//blog/2022/ai-atlas</id><content type="html" xml:base="https://timothee-schmude.github.io//blog/2022/ai-atlas/"><![CDATA[<p>I read the Atlas of AI, published in 2021 by Kate Crawford, and it is an astonishing read.</p> <p>We are all quite familiar with the public image of Artificial Intelligence. It is easy to associate the text-to-image generation model Dall-E with the term, or translation software like DeepL, recommender systems used by Netflix or YouTube, and various forms of personal assistants such as Alexa or Siri. Even robots turn out to be a common first thought when talking about AI. But the vital point that Atlas of AI makes is that AI has long eclipsed its usage in mere consumer products and tools. Artificial Intelligence, Kate Crawford argues, is conquering a ”much wider set of political and social structures” and is “ultimately designed to serve existing dominant interests”. In a profound analysis backed by tremendous amounts of research, the book reveals to us that AI is primarily a “registry of power”, and that we should beware.</p> <p>Crawford’s magnificent way of presenting us with this evidence is by telling stories that take us by the hand and say ‘Look, over there, this is the Silver Peak Lithium Mine, where residue from pumping up lithium brine gathers in large, toxic lakes.’, or ‘This is the Armour Beef dressing floor, where workers were the first to take their place in an assembly line, much as they do at Amazon today, where things are spiced up by automated time control.’ Not only are the examples historic, they are graphic, tangible, and they illustrate so well what is missing from our present conception of AI: The dirty, sweaty, greasy foundation on which it is built both materially, and, as it turns out, scientifically.</p> <p>The Chemetall Foote Lithium Operation in Clayton Valley. Photo by Magnus Manske.</p> <p>My favorite episode in this path of realization is Crawford’s visit to Samuel Morton’s cranial collection, a large amount of skulls gathered and labelled by the craniologist in the 19th century to explore if intelligence and “superiority” could be inferred from the size and structure of the human skull, establishing a deeply flawed and racist take on anatomy. This is the introduction to the book’s section on Classification and it is so rich in history and symbolism that it is nothing short of literary, and thus so suitable for the introduction of a central question: Who is the one holding the power to decide over what ought to be classified, and which classes to use? Of course, Crawford argues, the ones performing these classifications have rarely been the minorities and fringe groups, but the ruling class. It is no large leap of mind to realize that these classifications were not put in place in order to infringe on the ruling class’ control and influence, but to increase and cement them. The achievement of Atlas of AI is not only to unveil the bizarre building blocks of present-day AI, but also to steer these questions back to the present, connecting them to discussions about bias and surveillance. After taking in the historic panorama that Crawford develops before us, we lastly arrive at the present with a quaint little image of a skull that reminds us of where it all started.</p> <p>Labelled Skulls in Morton cranial collection.</p> <p>Boas, KC “The Curious Cabinet of Dr. Morton” Expedition Magazine 54.3 (2012): n. pag. Expedition Magazine. Penn Museum, 2012 Web. 16 Nov 2022.</p> <p>By leading us from the soil that is exploited for minerals to the integration of large-scale systems in government and military, Crawford carefully shows us how earth, labor, data, classification, state, power, and lastly, space, assume their roles as cogs in the large machinery that is AI. Each of these elements has secrets to tell and by the end we do not assume that anything about AI is without costs, only that they are hidden behind lofty curtains of marketing façade and a general, convenient confusion.</p> <p>I do not want to tell you all the brilliant bits in advance. If you are interested in Artificial Intelligence, working in the field, or reflecting on it, then I wholeheartedly recommend this book and indeed urge you to read it. I had not thought about tracing AI by notions of geography and history in this manner, showing us just how closely connected to political power it is, and so it is not overstating to say that Atlas of AI opened up my horizon by a considerable margin.</p> <p>Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. Kate Crawford, Yale University Press 2021.</p>]]></content><author><name></name></author><category term="posts"/><category term="books"/><summary type="html"><![CDATA[Book review of "AI Atlas"]]></summary></entry><entry><title type="html">Asking DALL·E About The Strongest Avenger; and Other Matters</title><link href="https://timothee-schmude.github.io//blog/2022/dall-e/" rel="alternate" type="text/html" title="Asking DALL·E About The Strongest Avenger; and Other Matters"/><published>2022-06-11T10:00:00+00:00</published><updated>2022-06-11T10:00:00+00:00</updated><id>https://timothee-schmude.github.io//blog/2022/dall-e</id><content type="html" xml:base="https://timothee-schmude.github.io//blog/2022/dall-e/"><![CDATA[<p>You’ve probably heard about <a href="https://openai.com/index/dall-e/">DALL·E</a>, the huge neural network generating images from text, built on top of another huge neural network that is famously well-versed in human language: the Generative Pre-Trained Transformer 3, or GPT-3. So famous, in fact, that OpenAI decided that AI should not be open after all and sealed GPT-3 behind a wall of exclusivity only to be conquered by formal application or by, you know, paying. People that got through this application step tell intriguing tales about all the things that can be done with the model, among them <a href="https://www.aiweirdness.com/gpt-3-tries-pickup-lines/">GPT-3 trying pickup lines</a>, <a href="https://medium.com/swlh/i-wrote-a-book-with-gpt-3-ai-in-24-hours-and-got-it-published-93cf3c96f120">GPT-3 writing books</a>, <a href="https://www.universityofcalifornia.edu/news/will-ai-write-next-great-american-novel">GPT-3 composing poetry</a> and <a href="https://www.reddit.com/r/artificial/comments/icvypl/list_of_free_sitesprograms_that_are_powered_by/">GPT-3 doing basically everything else</a>.</p> <p>Setting aside the slightly dystopian implications for the moment, OpenAI in January last year announced yet another machine learning model with impressive capability: DALL·E. This one can generate images from any text that you give it, that is, it takes your words and tries to render a visual interpretation of them. The resulting images are not unlike those from <a href="https://research.google/blog/inceptionism-going-deeper-into-neural-networks/">DeepDream</a> and <a href="https://thispersondoesnotexist.com">thispersondoesnotexist.com</a> (though those are different architectures). Apparently, the most intuitive thing to ask such a machine is to produce an image of a chair in the form of an avocado, which promptly became DALL·E’s emblem.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/avocado_chair-480.webp 480w,/assets/img/avocado_chair-800.webp 800w,/assets/img/avocado_chair-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/avocado_chair.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The Avocado chair. (Copyright @ OpenAI 2021, or DALL·E, I don't know which) </div> <p>The name DALL·E is doubly punned, referring to our cute little order-obsessed robot WALL-E and the surrealist painter Dalí at the same time, and makes clear the intended crossover of algorithmic structure and artistic vision bordering on the subconscious. In theory this should result in a singular view on the world: a direct transport line between verbal imagination and graphic depiction, heavily influenced by whatever transformation the model performs on the input. And indeed the results appear to live up to this promise. Whether it imagines something realistic, like a pentagonal clock, or something more extraordinary, like a snail harp (images Copyright @ OpenAI 2021).</p> <p><img src="https://media.licdn.com/dms/image/v2/D4E12AQFgiIhxKAZ2_w/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1654948404491?e=1746057600&amp;v=beta&amp;t=vvgjKoFjcy56pCFxGF6iwfs7vC2DBbNPtdy3duNiutI" alt="Green clock"/></p> <p><img src="https://media.licdn.com/dms/image/v2/D4E12AQEAbSeLC_M0IA/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1654948411676?e=1746057600&amp;v=beta&amp;t=FnIkQJfdVHQRyPU8Cy414VnuqxCLeMNCNqSfCNkivDc" alt="Snail harp"/></p> <p>One is well advised not to forget the human part about these image generations. GPT-3, DALL·E’s base model, was trained on numerous texts from the web (the so-called Common Crawl and the whole of Wikipedia) and a lot of books. “Numerous” is understating: they are gigantic amounts. Towering, unimaginable amounts, impossible to grasp – you know the scales. The point is: most of this is human language. Every piece of text has an author, a date of publication, a context, and human views and opinions embedded deeply into it. This is no bad thing! It just means that when we are looking at GPT-3’s output, we are looking at the (mostly intransparent) transformation of a large volume of human language, cast into a specific form, like a distillation of everything that was said in the last 100 years – by certain people, in certain places.</p> <p>On a side note: The process of transforming various inputs by the workings of an opaque machinery into something new actually sounds familiar – humans do it all the time. Of course, this is no clean analogy, there are multiple things we don’t understand about consciousness and the brain. Ironically though, we don’t understand everything about neural networks either. Our not-knowing how is a pretty straight parallel between the two concepts (and something we work on in <a href="[url](https://media.licdn.com/dms/image/v2/D4E12AQEAbSeLC_M0IA/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1654948411676?e=1746057600&amp;v=beta&amp;t=FnIkQJfdVHQRyPU8Cy414VnuqxCLeMNCNqSfCNkivDc)">our research project</a>).</p> <p>DALL·E was trained in a similar fashion to GPT-3: by collecting numerous text and image pairs from the internet, since it’s cheap and it’s there. One part comes from Wikipedia, the other part from Flickr. This means we get data from people hanging out on a) Wikipedia, and b) Flickr. Again, nothing to fret about necessarily, just something to keep in mind when looking at the applications of DALL·E. As a reminder, facial recognition systems couldn’t (or might still be unable to) handle images of black women as they were underrepresented in the training data. Thankfully, there are researchers occupying themselves with revealing and dealing with these discriminatory biases. Unluckily, big tech doesn’t always seem to like what they find and prefers to sanction them. Two prominent researches who left (or were made to leave) Google because of this are Margaret Mitchell and Timnit Gebru.</p> <p>Coming back to the practical part of the model, you certainly would like to try your hands at it yourself. Good news! There is a <a href="[url](https://huggingface.co/spaces/dalle-mini/dalle-mini)">mini version of DALL·E over at HuggingFace</a> that let’s you play around with it, it is slow and not as good as the original, but still a lot of fun. You can also build the thing yourself, if you want, they put the <a href="[url](https://github.com/borisdayma/dalle-mini)">code for DALL·E Mini on Github</a>. (HuggingFace really are accommodating in giving access)</p> <p>Alright, let’s see if it delivers! Avocado chairs and pentagon clocks fine and well, but what if we ask for things that can’t be pictured? Like the flavour of the sun?</p> <p><img src="https://media.licdn.com/dms/image/v2/D4E12AQEaZ5QTPObC9Q/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1654948498706?e=1746057600&amp;v=beta&amp;t=KvuKN8-Nv-F2SDv8ci3234pgZEv9p4AI7y1CfC6T6Qk" alt="Orange sun"/></p> <p>We could have figured there would be some orangey vibes in there. Let’s make it more abstract, let’s picture canonical thinking.</p> <p><img src="https://media.licdn.com/dms/image/v2/D4E12AQE9VDzuTYqboA/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1654948537650?e=1746057600&amp;v=beta&amp;t=SBIOEjWO5C435P0SoOY8J3xbzbYRW0gKiPDLcbj8Vdc" alt="Canonical thinking"/></p> <p>Whatever it is, the pope appears to have a part in it, and he really makes an effort, too. Not too surprising when you look at the meanings of “canonical”. One could make a sublime joke about the “literature pope” Marcel Reich-Ranicki, as he was called, who published the canon for German literature, but I think that’s going too far.</p> <p>Let’s see what DALL·E does with something even more vague, a certain way of death, that the universe faces, provided some peculiar part of physics will turn out a specific way, the vacuum decay. In short, a bubble with a better energetic state than the present one that forms somewhere in space and makes everything nonexistent very quickly. No alt text provided for this image</p> <p>Yep, that’s not so far off. There are bubbles, certainly, and Wikipedia has an image that virtually looks the same (don’t be confused it actually shows the Cosmic Microwave Background), so let’s settle on that being a truthful depiction of <a href="https://en.wikipedia.org/wiki/False_vacuum">vacuum decay</a>, no one can prove otherwise anyway.</p> <p><img src="https://media.licdn.com/dms/image/v2/D4E12AQHdzZeuWJLQDw/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1654948611176?e=1746057600&amp;v=beta&amp;t=l_ULa2uxIoeUVQqO7cQrAIASSfF74X8ootfYOYb-njE" alt="Vacuum decay"/></p> <p>Two to go, ordered by difficulty to answer. First one: Who is the strongest avenger?</p> <p><img src="https://media.licdn.com/dms/image/v2/D4E12AQFVnFmFx6Q7QQ/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1654948656402?e=1746057600&amp;v=beta&amp;t=LF_7TeiKS1MlFvgGdGRmPf7I7W3GH8q_s0qvaT68cB8" alt="Strongest avenger"/></p> <p>Kind of all of them, I guess. Though Iron Man plays a central role, but maybe that’s just nostalgia.</p> <p>Last question for the mini-AI-oracle and for our little excursion into strange AI imagination: What does life after death look like?</p> <p><img src="https://media.licdn.com/dms/image/v2/D4E12AQGnK9TvkrPcUw/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1654948682447?e=1746057600&amp;v=beta&amp;t=yYaNN5or6uMDKDCwWDnWrnmqxzTwsXkcGYyz20XgZiU" alt="Life after death"/></p> <p>There is light, dark figures and a black vignette. If you do a google image search you will see that this is rather prototypical. Still, as a distillation of human ideas about life after death, this is not bad at all. As someone who also dove into literature analysis a couple of times, the possibility of interpreting symbolism and composition of these images is very intriguing. Incidentally, I have done something similar in my master’s thesis, but that’s a story for another time.</p> <p>Suppose we had a fully working model of DALL·E, imagine the implications. Every photograph, be it for ads or articles, could be generated, every book cover, every movie poster, theoretically, every frame of a movie as well. This is science fiction, of course, but it slowly transcends into the realm of reality. Indeed, if you can make a profit on it, the thing is shoved into reality in the bat of an eye. And what do you know, there is a new version already! OpenAI presents: <a href="https://openai.com/index/dall-e-2/">DALL·E 2</a>.</p> <p>The important question is, if AI was perfect, and if AI could generate every image possible, would you still look at a human one?</p>]]></content><author><name></name></author><category term="posts"/><category term="genAI"/><summary type="html"><![CDATA[Playing around with image generating AI]]></summary></entry></feed>